---
layout: single
title: "Linear Regression vs Logistic Regression"
category: machine-learning
tag: ML
toc: true
author_profile: false
sidebar:
    nav: "docs"
mathjax: true
---

**[Notice]** [Welcome!](https://dae-y.github.io/notice/first/)
{: .notice--success}

A quick table for Linear Reg vs Logistic Reg

| Feature             | Linear Regression               | Logistic Regression (Classification) |
|---------------------|--------------------------------|--------------------------------------|
| **Data (Output)**   | Continuous Values             | Discrete Categories (Probabilities) |
| **Loss Function**   | Mean Squared Error (MSE)      | Cross-Entropy Loss (Binary)         |
| **Optimization**    | Gradient Descent              | Gradient Descent                    |
| **Classification**  | Not Applicable               | Probability-based (Threshold 0.5)   |
| **Primary Use**     | Prediction of Continuous Values | Classification (Binary or Multi-class) |

The model equations:

- Linear Regression:  
  $$ y = wx + b $$

- Logistic Regression:  
  $$ y = \frac{1}{1 + e^{-(wx + b)}} $$

<script type="text/javascript" async
  src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-MML-AM_CHTML">
</script>
